{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL Unplugged: Offline DQN - Atari Frostbite",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JFHwang/deepmind-research/blob/master/rl_unplugged/atari_dqn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDiJzbb8KFvP"
      },
      "source": [
        "Copyright 2020 DeepMind Technologies Limited.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use\n",
        "this file except in compliance with the License. You may obtain a copy of the\n",
        "License at\n",
        "\n",
        "[https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed\n",
        "under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n",
        "CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
        "specific language governing permissions and limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULdrhOaVbsdO"
      },
      "source": [
        "# RL Unplugged: Offline DQN - Atari\n",
        "## Guide to  training an Acme DQN agent on Atari data.\n",
        "# <a href=\"https://colab.research.google.com/github/deepmind/deepmind_research/blob/master/rl_unplugged/atari_dqn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaJxoatMhJ71"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "KH3O0zcXUeun"
      },
      "source": [
        "!pip install dm-acme==0.2.0\n",
        "!pip install dm-acme[reverb]==0.2.0\n",
        "!pip install dm-acme[tf]==0.2.0\n",
        "!pip install dm-sonnet\n",
        "!pip install dopamine-rl==3.1.2\n",
        "!pip install atari-py\n",
        "!git clone https://github.com/deepmind/deepmind-research.git\n",
        "%cd deepmind-research"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeZ-ct0B6vdP"
      },
      "source": [
        "!wget http://www.atarimania.com/roms/Roms.rar\n",
        "!mkdir roms\n",
        "!unrar e Roms.rar roms\n",
        "!python -m atari_py.import_roms roms/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-H2d6UZi7Sf"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "HJ74Id-8MERq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ed1733-5040-4332-c932-440a96d09a2c"
      },
      "source": [
        "%cd /content/deepmind-research\n",
        "import copy\n",
        "\n",
        "import acme\n",
        "import rl_unplugged\n",
        "from acme.agents.tf import actors\n",
        "from acme.agents.tf.dqn import learning as dqn\n",
        "from acme.tf import utils as acme_utils\n",
        "from acme.utils import loggers\n",
        "from rl_unplugged import atari\n",
        "import sonnet as snt\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deepmind-research\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Argument blacklist is deprecated. Please use denylist.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlwyo9K1s6GP"
      },
      "source": [
        "##Setting Parameters\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdVOwKmqsqhU"
      },
      "source": [
        "game = 'BattleZone' #@param\n",
        "shardcount = 100#@param\n",
        "run =   1#@param\n",
        "tmp_path = '/tmp/dataset'\n",
        "gs_path = 'gs://rl_unplugged/atari'\n",
        "!mkdir -p {tmp_path}/{game}\n",
        "environment = atari.environment(game=game)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrOSnoWiY4Xl"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvk9AwzBIDMs"
      },
      "source": [
        "if shardcount < 100:\n",
        "\n",
        "  # If not enough disk space, only copy subset of samples\n",
        "  for i in range(shardcount/10):\n",
        "    !gsutil -m cp -R gs://rl_unplugged/atari/{game}/run_{run}-00{i}* /tmp/dataset/{game}\n",
        "\n",
        "  for shard in range(shardcount):\n",
        "    fshard = \"{:05d}\".format(shard)\n",
        "    fshardcount = \"{:05d}\".format(shardcount)\n",
        "    !mv /tmp/dataset/{game}/run_{run}-{fshard}-of-00100 /tmp/dataset/{game}/run_{run}-{fshard}-of-{fshardcount}\n",
        "\n",
        "else:\n",
        "  # Copy all 100 shards\n",
        "  !gsutil -m cp -R gs://rl_unplugged/atari/{game}/run_{run}* /tmp/dataset/{game}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCnSQpVG4T3n"
      },
      "source": [
        "##Create Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Jcjk1w6oHVX",
        "outputId": "eafd1504-fa04-4a04-8fbc-ab8e0a01f03b"
      },
      "source": [
        "# Get total number of actions.\n",
        "num_actions = environment.action_spec().num_values\n",
        "\n",
        "# Create the Q network.\n",
        "network = snt.Sequential([\n",
        "    lambda x: tf.image.convert_image_dtype(x, tf.float32),\n",
        "    snt.Conv2D(32, [8, 8], [4, 4]),\n",
        "    tf.nn.relu,\n",
        "    snt.Conv2D(64, [4, 4], [2, 2]),\n",
        "    tf.nn.relu,\n",
        "    snt.Conv2D(64, [3, 3], [1, 1]),\n",
        "    tf.nn.relu,\n",
        "    snt.Flatten(),\n",
        "    snt.nets.MLP([512, num_actions])\n",
        "])\n",
        "acme_utils.create_variables(network, [environment.observation_spec()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorSpec(shape=(18,), dtype=tf.float32, name=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BukOfOsmtSQn"
      },
      "source": [
        "## DQN learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN4iQkjjPD7o"
      },
      "source": [
        "batch_size = 32#@param\n",
        "\n",
        "def discard_extras(sample):\n",
        "  return sample._replace(data=sample.data[:5])\n",
        "\n",
        "#Organize files into dataset. tuples of length 5 and batches of 32 tuples.\n",
        "dataset = atari.dataset(path=tmp_path, game=game, run=run, num_shards=shardcount)\n",
        "dataset = dataset.map(discard_extras).batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b2QuZDGPOL3"
      },
      "source": [
        "##DQN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CD2sNK-oA9S"
      },
      "source": [
        "# Create a logger.\n",
        "logger = loggers.TerminalLogger(label='learner', time_delta=60.)\n",
        "\n",
        "# Create the DQN learner.\n",
        "learner = dqn.DQNLearner(\n",
        "    network=network,\n",
        "    target_network=copy.deepcopy(network),\n",
        "    discount=0.99,\n",
        "    learning_rate=25e-5,\n",
        "    importance_sampling_exponent=0.2,\n",
        "    target_update_period=8000,\n",
        "    dataset=dataset,\n",
        "    logger=logger)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKeGQxzitXYC"
      },
      "source": [
        "## Training and Eval Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rba2pxBRUIls"
      },
      "source": [
        "iterations = 20#@param\n",
        "# Create a logger.\n",
        "logger = loggers.TerminalLogger(label='evaluation', time_delta=1.)\n",
        "\n",
        "for iteration in range(iterations):\n",
        "  # Training Loop\n",
        "  for _ in range(250000):\n",
        "    learner.step()\n",
        "\n",
        "\n",
        "  # Create an environment loop.\n",
        "  policy_network = snt.Sequential([\n",
        "      network,\n",
        "      lambda q: tf.argmax(q, axis=-1),\n",
        "  ])\n",
        "  loop = acme.EnvironmentLoop(\n",
        "      environment=environment,\n",
        "      actor=actors.FeedForwardActor(policy_network=policy_network),\n",
        "      logger=logger)\n",
        "\n",
        "  loop.run(20)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}